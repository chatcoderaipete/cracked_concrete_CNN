import os
import shutil
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Function to create directories and split files
def create_and_split_data(base_dir, category, train_size=0.7, eval_size=0.15):
    # Create directories
    os.makedirs(os.path.join(base_dir, 'Training', category), exist_ok=True)
    os.makedirs(os.path.join(base_dir, 'Evaluation', category), exist_ok=True)
    os.makedirs(os.path.join(base_dir, 'Testing', category), exist_ok=True)

    # List all files in the original directory
    files = os.listdir(os.path.join(base_dir, category))
    np.random.shuffle(files)  # Shuffle the files randomly

    # Split files
    train_files = files[:int(len(files) * train_size)]
    eval_files = files[int(len(files) * train_size):int(len(files) * (train_size + eval_size))]
    test_files = files[int(len(files) * (train_size + eval_size)):]

    # Function to copy files to a target directory
    def copy_files(files, target_dir):
        for file in files:
            shutil.copy(os.path.join(base_dir, category, file), os.path.join(target_dir, file))

    # Copy files to respective directories
    copy_files(train_files, os.path.join(base_dir, 'Training', category))
    copy_files(eval_files, os.path.join(base_dir, 'Evaluation', category))
    copy_files(test_files, os.path.join(base_dir, 'Testing', category))

# Define a function to preprocess the data
def preprocess_data(base_dir, target_size=(224, 224), batch_size=32):
    # Data generator configurations
    train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,
                                       height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,
                                       horizontal_flip=True, fill_mode='nearest')
    test_datagen = ImageDataGenerator(rescale=1./255)

    # Create data generators
    train_generator = train_datagen.flow_from_directory(os.path.join(base_dir, 'Training'),
                                                        target_size=target_size, batch_size=batch_size,
                                                        class_mode='binary')
    validation_generator = test_datagen.flow_from_directory(os.path.join(base_dir, 'Evaluation'),
                                                            target_size=target_size, batch_size=batch_size,
                                                            class_mode='binary')
    test_generator = test_datagen.flow_from_directory(os.path.join(base_dir, 'Testing'),
                                                      target_size=target_size, batch_size=batch_size,
                                                      class_mode='binary')
    return train_generator, validation_generator, test_generator

# Create and split the data
base_dir = 'C:\\Users\\pete\\Documents\\datafile\\Concrete Crack Images for Classification'
create_and_split_data(base_dir, 'Positive')
create_and_split_data(base_dir, 'Negative')

# Preprocess the data
train_gen, val_gen, test_gen = preprocess_data(base_dir)

# Initialize and compile the model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_gen, steps_per_epoch=train_gen.samples // train_gen.batch_size, epochs=10,
                    validation_data=val_gen, validation_steps=val_gen.samples // val_gen.batch_size)

# Evaluate and save the model
test_loss, test_accuracy = model.evaluate(test_gen, steps=test_gen.samples // test_gen.batch_size)
print(f"Test accuracy: {test_accuracy}, Test loss: {test_loss}")
model.save('concrete_crack_detection_model.h5')
